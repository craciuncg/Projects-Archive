{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\cristi\\appdata\\roaming\\python\\python39\\site-packages (2.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Program files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!py -3.9 -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintext: 11011010\n",
      "Key: 1010000010\n",
      "Encrypted Text: 11100001\n"
     ]
    }
   ],
   "source": [
    "def permute(original, order):\n",
    "    \"\"\"Permute the bits of the original according to the specified order.\"\"\"\n",
    "    return ''.join(original[i - 1] for i in order)\n",
    "\n",
    "def generate_subkeys(key):\n",
    "    \"\"\"Generate 8-bit subkeys for S-DES.\"\"\"\n",
    "    p10 = [3, 5, 2, 7, 4, 10, 1, 9, 8, 6]\n",
    "    p8 = [6, 3, 7, 4, 8, 5, 10, 9]\n",
    "\n",
    "    # Apply the initial permutation (P10)\n",
    "    key = permute(key, p10)\n",
    "\n",
    "    # Split the key into two halves\n",
    "    left_half = key[:5]\n",
    "    right_half = key[5:]\n",
    "\n",
    "    # Perform the first circular left shift on each half\n",
    "    left_half = left_half[1:] + left_half[0]\n",
    "    right_half = right_half[1:] + right_half[0]\n",
    "\n",
    "    # Combine the halves\n",
    "    combined_half = left_half + right_half\n",
    "\n",
    "    # Apply the permutation (P8) to generate the first subkey\n",
    "    subkey1 = permute(combined_half, p8)\n",
    "\n",
    "    # Perform a second circular left shift on each half\n",
    "    left_half = left_half[2:] + left_half[:2]\n",
    "    right_half = right_half[2:] + right_half[:2]\n",
    "\n",
    "    # Combine the halves\n",
    "    combined_half = left_half + right_half\n",
    "\n",
    "    # Apply the permutation (P8) to generate the second subkey\n",
    "    subkey2 = permute(combined_half, p8)\n",
    "\n",
    "    return subkey1, subkey2\n",
    "\n",
    "def initial_permutation(block):\n",
    "    \"\"\"Perform the initial permutation (IP) on the 8-bit block.\"\"\"\n",
    "    ip = [2, 6, 3, 1, 4, 8, 5, 7]\n",
    "    return permute(block, ip)\n",
    "\n",
    "def inverse_permutation(block):\n",
    "    \"\"\"Perform the inverse permutation (IP^-1) on the 8-bit block.\"\"\"\n",
    "    ip_inverse = [4, 1, 3, 5, 7, 2, 8, 6]\n",
    "    return permute(block, ip_inverse)\n",
    "\n",
    "def expansion_permutation(block):\n",
    "    \"\"\"Perform the expansion permutation (EP) on the 4-bit block.\"\"\"\n",
    "    ep = [4, 1, 2, 3, 2, 3, 4, 1]\n",
    "    return permute(block, ep)\n",
    "\n",
    "def substitution_box(input_4bit):\n",
    "    \"\"\"Perform the substitution box operation (S-Box) on the 4-bit input.\"\"\"\n",
    "    s_box = [\n",
    "        [[1, 0], [0, 3], [3, 2], [2, 1]],\n",
    "        [[2, 1], [1, 0], [0, 3], [3, 2]],\n",
    "        [[3, 2], [2, 1], [1, 0], [0, 3]],\n",
    "        [[0, 3], [3, 2], [2, 1], [1, 0]]\n",
    "    ]\n",
    "\n",
    "    row = int(input_4bit[0] + input_4bit[3], 2)\n",
    "    col = int(input_4bit[1:3], 2)\n",
    "\n",
    "    return format(s_box[row][col][0], '02b') + format(s_box[row][col][1], '02b')\n",
    "\n",
    "def f_function(right_half, subkey):\n",
    "    \"\"\"Perform the F function on the 4-bit right half.\"\"\"\n",
    "    # Expansion permutation\n",
    "    expanded_right = expansion_permutation(right_half)\n",
    "\n",
    "    # XOR with subkey\n",
    "    expanded_right_xor_subkey = ''.join(str(int(a) ^ int(b)) for a, b in zip(expanded_right, subkey))\n",
    "\n",
    "    # Substitution box (S-Box)\n",
    "    s_box_output = substitution_box(expanded_right_xor_subkey)\n",
    "\n",
    "    return s_box_output\n",
    "\n",
    "def round_function(block, subkey):\n",
    "    \"\"\"Perform one round of S-DES.\"\"\"\n",
    "    left_half, right_half = block[:4], block[4:]\n",
    "\n",
    "    # F function\n",
    "    f_output = f_function(right_half, subkey)\n",
    "\n",
    "    # XOR with left half\n",
    "    new_right_half = ''.join(str(int(a) ^ int(b)) for a, b in zip(left_half, f_output))\n",
    "\n",
    "    # Swap left and right halves\n",
    "    new_left_half = right_half\n",
    "    new_block = new_left_half + new_right_half\n",
    "\n",
    "    return new_block\n",
    "\n",
    "def sdes_encrypt(plaintext, key):\n",
    "    \"\"\"Encrypt the plaintext using S-DES.\"\"\"\n",
    "    key = format(int(key, 2), '010b')  # Convert key to 10-bit binary\n",
    "    plaintext = format(int(plaintext, 2), '08b')  # Convert plaintext to 8-bit binary\n",
    "\n",
    "    # Generate subkeys\n",
    "    subkey1, subkey2 = generate_subkeys(key)\n",
    "\n",
    "    # Initial permutation\n",
    "    permuted_text = initial_permutation(plaintext)\n",
    "\n",
    "    # Round 1\n",
    "    permuted_text = round_function(permuted_text, subkey1)\n",
    "\n",
    "    # Swap halves\n",
    "    permuted_text = permuted_text[4:] + permuted_text[:4]\n",
    "\n",
    "    # Round 2\n",
    "    permuted_text = round_function(permuted_text, subkey2)\n",
    "\n",
    "    # Inverse permutation\n",
    "    ciphertext = inverse_permutation(permuted_text)\n",
    "\n",
    "    return format(int(ciphertext, 2), '08b')\n",
    "\n",
    "# Example usage\n",
    "plaintext = '11011010'\n",
    "key = '1010000010'\n",
    "\n",
    "encrypted_text = sdes_encrypt(plaintext, key)\n",
    "print(\"Plaintext:\", plaintext)\n",
    "print(\"Key:\", key)\n",
    "print(\"Encrypted Text:\", encrypted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "N_TRAIN = 55000\n",
    "N_VAL = 30000\n",
    "N_TEST = 15000\n",
    "\n",
    "M = 8\n",
    "L = 10\n",
    "\n",
    "def random_binary(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def generate_dataset(encrypt, N, name):\n",
    "    plains = []\n",
    "    ciphers = []\n",
    "    keys = []\n",
    "    \n",
    "    for _ in range(N):\n",
    "        plain = random_binary(M)\n",
    "        key = random_binary(L)\n",
    "        cipher = encrypt(plain, key)\n",
    "        \n",
    "        plains.append(plain)\n",
    "        ciphers.append(cipher)\n",
    "        keys.append(key)\n",
    "    \n",
    "    df = pd.DataFrame({'Plaintext' : plains, 'Ciphertext' : ciphers, 'Key' : keys})\n",
    "    df.to_csv(name, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "generate_dataset(sdes_encrypt, N_TRAIN, 'S-DES-TRAIN.csv')\n",
    "\n",
    "# Validation\n",
    "generate_dataset(sdes_encrypt, N_VAL, 'S-DES-VAL.csv')\n",
    "\n",
    "# Testing\n",
    "generate_dataset(sdes_encrypt, N_TEST, 'S-DES-TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "details.get('device_name', 'Unknown GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "M = 8\n",
    "L = 10\n",
    "\n",
    "def embed(df):\n",
    "  df['Input'] = df['Plaintext'].astype(str) + df['Ciphertext']\n",
    "  df = df.drop(columns=['Plaintext', 'Ciphertext'])\n",
    "\n",
    "  df['Key'] = df['Key'].apply(lambda x : np.array(list(map(int, list(x))), dtype=np.float32))\n",
    "  df['Input'] = df['Input'].apply(lambda x : np.array(list(map(int, list(x))), dtype=np.float32))\n",
    "\n",
    "  input = np.vstack(df['Input'].to_numpy())\n",
    "  key = np.vstack(df['Key'].to_numpy())\n",
    "\n",
    "  return input, key\n",
    "\n",
    "dtype_mapping = {\n",
    "    'Plaintext' : str,\n",
    "    'Ciphertext' : str,\n",
    "    'Key' : str\n",
    "}\n",
    "# Training\n",
    "df_train = pd.read_csv('S-DES-TRAIN.csv', dtype=dtype_mapping)\n",
    "\n",
    "# Validation\n",
    "df_val = pd.read_csv('S-DES-VAL.csv', dtype=dtype_mapping)\n",
    "\n",
    "# Testing\n",
    "df_test = pd.read_csv('S-DES-TEST.csv', dtype=dtype_mapping)\n",
    "\n",
    "train_input, train_key = embed(df_train)\n",
    "val_input, val_key = embed(df_val)\n",
    "test_input, test_key = embed(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "initializer='truncated_normal'\n",
    "\n",
    "class GLU(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(GLU, self).__init__()\n",
    "        self.units = units\n",
    "        self.output_layer = layers.Dense(2 * units, activation=None, trainable=True, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_output = self.output_layer(inputs)\n",
    "        return tf.multiply(linear_output[:, :self.units], tf.keras.activations.sigmoid(linear_output[:, self.units:]))\n",
    "\n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.size = size\n",
    "        \n",
    "        activation=None\n",
    "        \n",
    "        self.input_layer = layers.Dense(16, activation=activation, trainable=True, kernel_initializer=initializer)\n",
    "        \n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.linear1 = layers.Dense(size, activation=activation, trainable=True, kernel_initializer=initializer)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.linear2 = layers.Dense(size, activation=activation, trainable=True, kernel_initializer=initializer)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.linear3 = layers.Dense(size, activation=activation, trainable=True, kernel_initializer=initializer)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.linear4 = layers.Dense(size, activation=activation, trainable=True, kernel_initializer=initializer)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.input_layer(inputs)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        y = self.bn3(x)\n",
    "        y = tf.keras.activations.relu(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.bn4(y)\n",
    "        y = tf.keras.activations.relu(y)\n",
    "        y = self.linear4(y)\n",
    "        \n",
    "        z = x + y\n",
    "        return z\n",
    "        \n",
    "\n",
    "class SDESModel(tf.keras.Model):\n",
    "    def __init__(self, size):\n",
    "        super(SDESModel, self).__init__()\n",
    "        self.size = size\n",
    "        \n",
    "        self.block = ResidualBlock(size)\n",
    "        self.glu = GLU(10)\n",
    "        \n",
    "        self.output_layer = layers.Dense(10, trainable=True, activation='relu', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.block(inputs)\n",
    "        y = self.glu(x)\n",
    "        \n",
    "        return self.output_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xnor_layer(tensor1, tensor2):\n",
    "    # Convert tensors to boolean values\n",
    "    bool_tensor1 = tf.math.greater_equal(tensor1, 0.5)  # Assuming values >= 0.5 are considered True\n",
    "    bool_tensor2 = tf.math.greater_equal(tensor2, 0.5)\n",
    "\n",
    "    # Perform logical AND and logical OR operations\n",
    "    logical_and = tf.math.logical_and(bool_tensor1, bool_tensor2)\n",
    "    logical_or = tf.math.logical_or(tf.math.logical_not(bool_tensor1), tf.math.logical_not(bool_tensor2))\n",
    "\n",
    "    # Perform logical NOT operation\n",
    "    xnor_result = tf.math.logical_not(tf.math.logical_or(logical_and, logical_or))\n",
    "\n",
    "    # Convert boolean result back to float32\n",
    "    xnor_result = tf.cast(xnor_result, tf.float32)\n",
    "\n",
    "    return xnor_result\n",
    "\n",
    "def BAP(predictions, targets, l):\n",
    "  k = targets[:, l]\n",
    "  k_pred = (predictions[:, l] >= 0.5).float()\n",
    "\n",
    "  return tf.reduce_sum(xnor_layer(k, k_pred)) / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 150\n",
    "BATCH_SIZE = len(df_train)\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "final_learning_rate = 0.1\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/NUM_EPOCHS)\n",
    "steps_per_epoch = int(len(df_train)/BATCH_SIZE)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDESModel(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4903 - accuracy: 0.0503\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 900.7255 - accuracy: 0.1244\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.5003\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4994 - accuracy: 0.5003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input, train_key, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 1., 0., 1., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1786572 , 0.17420608, 0.18691818, 0.20201515, 0.17594269,\n",
       "       0.19635528, 0.18544662, 0.18409753, 0.20407243, 0.18878058],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
